{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_name = \"baseline.classifier.cnn_4_retinas.sig56_vs_bg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"device=gpu3\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env THEANO_FLAGS=\"device=gpu3\"\n",
    "\n",
    "import sys,os\n",
    "sys.path.append(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import theano stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess/Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata does not exist. This run might be MUCH longer due to preprocessing the data.\n"
     ]
    }
   ],
   "source": [
    "from config import from_data\n",
    "data_path_sig = from_data(\"sig56/\")\n",
    "data_path_bg_up = from_data(\"bg_up/\")\n",
    "data_path_bg_down = from_data(\"bg_down/\")\n",
    "metadata_path = from_data(\"k0s_event_identification\")\n",
    "\n",
    "\n",
    "generate_metadata = not os.path.exists(metadata_path)\n",
    "if generate_metadata:\n",
    "    print \"Metadata does not exist. This run might be MUCH longer due to preprocessing the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing events: 100/10000\n",
      "processing events: 200/10000\n",
      "processing events: 300/10000\n",
      "processing events: 400/10000\n",
      "processing events: 500/10000\n",
      "processing events: 600/10000\n",
      "processing events: 700/10000\n",
      "processing events: 800/10000\n",
      "processing events: 900/10000\n",
      "processing events: 1000/10000\n",
      "processing events: 1100/10000\n",
      "processing events: 1200/10000\n",
      "processing events: 1300/10000\n",
      "processing events: 1400/10000\n",
      "processing events: 1500/10000\n",
      "processing events: 1600/10000\n",
      "processing events: 1700/10000\n",
      "processing events: 1800/10000\n",
      "processing events: 1900/10000\n",
      "processing events: 2000/10000\n",
      "processing events: 2100/10000\n",
      "processing events: 2200/10000\n",
      "processing events: 2300/10000\n",
      "processing events: 2400/10000\n",
      "processing events: 2500/10000\n",
      "processing events: 2600/10000\n",
      "processing events: 2700/10000\n",
      "processing events: 2800/10000\n",
      "processing events: 2900/10000\n",
      "processing events: 3000/10000\n",
      "processing events: 3100/10000\n",
      "processing events: 3200/10000\n",
      "processing events: 3300/10000\n",
      "processing events: 3400/10000\n",
      "processing events: 3500/10000\n",
      "processing events: 3600/10000\n",
      "processing events: 3700/10000\n",
      "processing events: 3800/10000\n",
      "processing events: 3900/10000\n",
      "processing events: 4000/10000\n",
      "processing events: 4100/10000\n",
      "processing events: 4200/10000\n",
      "processing events: 4300/10000\n",
      "processing events: 4400/10000\n",
      "processing events: 4500/10000\n",
      "processing events: 4600/10000\n",
      "processing events: 4700/10000\n",
      "processing events: 4800/10000\n",
      "processing events: 4900/10000\n",
      "processing events: 5000/10000\n",
      "processing events: 5100/10000\n",
      "processing events: 5200/10000\n",
      "processing events: 5300/10000\n",
      "processing events: 5400/10000\n",
      "processing events: 5500/10000\n",
      "processing events: 5600/10000\n",
      "processing events: 5700/10000\n",
      "processing events: 5800/10000\n",
      "processing events: 5900/10000\n",
      "processing events: 6000/10000\n",
      "processing events: 6100/10000\n",
      "processing events: 6200/10000\n",
      "processing events: 6300/10000\n",
      "processing events: 6400/10000\n",
      "processing events: 6500/10000\n",
      "processing events: 6600/10000\n",
      "processing events: 6700/10000\n",
      "processing events: 6800/10000\n",
      "processing events: 6900/10000\n",
      "processing events: 7000/10000\n",
      "processing events: 7100/10000\n",
      "processing events: 7200/10000\n",
      "processing events: 7300/10000\n",
      "processing events: 7400/10000\n",
      "processing events: 7500/10000\n",
      "processing events: 7600/10000\n",
      "processing events: 7700/10000\n",
      "processing events: 7800/10000\n",
      "processing events: 7900/10000\n",
      "processing events: 8000/10000\n",
      "processing events: 8100/10000\n",
      "processing events: 8200/10000\n",
      "processing events: 8300/10000\n",
      "processing events: 8400/10000\n",
      "processing events: 8500/10000\n",
      "processing events: 8600/10000\n",
      "processing events: 8700/10000\n",
      "processing events: 8800/10000\n",
      "processing events: 8900/10000\n",
      "processing events: 9000/10000\n",
      "processing events: 9100/10000\n",
      "processing events: 9200/10000\n",
      "processing events: 9300/10000\n",
      "processing events: 9400/10000\n",
      "processing events: 9500/10000\n",
      "processing events: 9600/10000\n",
      "processing events: 9700/10000\n",
      "processing events: 9800/10000\n",
      "processing events: 9900/10000\n",
      "processing events: 100/5000\n",
      "processing events: 200/5000\n",
      "processing events: 300/5000\n"
     ]
    }
   ],
   "source": [
    "from lib.retina_compiled import retina_view, retinize_events\n",
    "import random\n",
    "get_random_ids = lambda path,k: random.sample(set(map(lambda s: s.split('.')[0],os.listdir(path))), k)\n",
    "\n",
    "\n",
    "\n",
    "retina_images_path = os.path.join(metadata_path,\"retina_images.npy\")\n",
    "answers_path = os.path.join(metadata_path,\"sig_or_bg.npy\")\n",
    "\n",
    "if generate_metadata:\n",
    "    \n",
    "\n",
    "\n",
    "    param_df = pd.DataFrame.from_csv(from_data(\"retinas/sig_vs_bg_0.csv\"))\n",
    "    retinas = [retina_view(*params) for params in param_df.values]\n",
    "\n",
    "\n",
    "    \n",
    "    sample_names = [\"signal\",\"bg_up\",\"bg_down\"]\n",
    "\n",
    "    sample_sizes = [10000,5000,5000]\n",
    "\n",
    "    y = map(np.repeat, sample_names,sample_sizes)\n",
    "    y = np.concatenate(y)\n",
    "\n",
    "    data_paths = [data_path_sig,data_path_bg_up,data_path_bg_down]\n",
    "\n",
    "    random.seed(7331)\n",
    "    #event ids : \"{runnumber}_{eventnumber}\"\n",
    "    data_runids = map(get_random_ids,data_paths,sample_sizes)\n",
    "\n",
    "    data_X = [\n",
    "        retinize_events(ids_i,path_i,retina_views=retinas,\n",
    "                                 max_hits_block=15000,report_rate=100)\n",
    "        for ids_i,path_i in zip(data_runids,data_paths)\n",
    "    ]\n",
    "\n",
    "    X = np.concatenate(data_X)\n",
    "\n",
    "\n",
    "    y = np.concatenate(map(np.repeat, sample_names,sample_sizes))\n",
    "    \n",
    "    \n",
    "    os.mkdir(metadata_path)\n",
    "    np.save(retina_images_path,X)\n",
    "    np.save(answers_path, y)\n",
    "    \n",
    "    generate_metadata = False\n",
    "else:\n",
    "    #load metadata\n",
    "    X = np.load(retina_images_path)\n",
    "    y = np.load(answers_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.reshape([len(X),-1,32,32])\n",
    "\n",
    "X = X.astype(\"float32\")\n",
    "y = (y==\"signal\").astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500,) (1500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "Xtr, Xts, Ytr,Yts = train_test_split(X,y,test_size=0.25,random_state=1337)\n",
    "\n",
    "print Ytr.shape,Yts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "floatX = theano.config.floatX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dim = (None,)+X.shape[1:]\n",
    "\n",
    "retina_dim = (None,1) + X.shape[2:]\n",
    "\n",
    "retina_images = T.tensor4(\"input_images\",\"floatX\")\n",
    "\n",
    "any_interesting_decays = T.ivector(\"event_has_k0s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concatenated_retinas = retina_images.reshape([retina_images.shape[0],1,-1,retina_images.shape[-1]])\n",
    "\n",
    "concatenated_dim = (None,1,np.prod(X.shape[1:-1]),X.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import MaxPool2DLayer as PoolLayer\n",
    "from lasagne.layers import DenseLayer, DropoutLayer\n",
    "\n",
    "#nn where each retina is processed with a separate CNN\n",
    "\n",
    "net = {}\n",
    "\n",
    "net['input'] = InputLayer(concatenated_dim,input_var=concatenated_retinas)\n",
    "net['conv1_1'] = ConvLayer(\n",
    "            net['input'], 256, 5, pad=1, flip_filters=False)\n",
    "net['pool1'] = PoolLayer(net['conv1_1'], 3)\n",
    "net['conv2_1'] = ConvLayer(\n",
    "            net['pool1'], 256, 5, pad=1, flip_filters=False)\n",
    "net['pool2'] = PoolLayer(net['conv2_1'], 3)\n",
    "    \n",
    "net['fc6'] = DenseLayer(net[\"pool2\"], num_units=1024)\n",
    "#net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.1)\n",
    "\n",
    "net['out'] = DenseLayer(net['fc6'], num_units=2, \n",
    "                        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, W, b, W, b]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = lasagne.layers.get_all_params(net[\"out\"],trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_prediction = lasagne.layers.get_output(net[\"out\"])\n",
    "train_loss_ce = lasagne.objectives.categorical_crossentropy(train_prediction,any_interesting_decays).mean()\n",
    "train_accuracy = lasagne.objectives.categorical_accuracy(train_prediction,any_interesting_decays).mean()\n",
    "updates = lasagne.updates.rmsprop(train_loss_ce,weights,learning_rate=0.001) \n",
    "#ik that lr does not matter. I just dont want an explosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fun = theano.function([retina_images,any_interesting_decays],[train_loss_ce,train_accuracy,train_prediction[:,1]], updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = lasagne.layers.get_output(net[\"out\"],deterministic=True)\n",
    "loss_ce = lasagne.objectives.categorical_crossentropy(prediction,any_interesting_decays).mean()\n",
    "accuracy = lasagne.objectives.categorical_accuracy(prediction,any_interesting_decays).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_fun = theano.function([retina_images,any_interesting_decays], [loss_ce,accuracy,prediction[:,1]])\n",
    "predict_fun = theano.function([retina_images],prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main loop\n",
    "* almost copies the layout of lasagne basic training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False,crop_at=None):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if crop_at == start_idx:\n",
    "            break\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 10.665s\n",
      "  training loss:\t\t89.153786\n",
      "  training accuracy:\t\t0.54 %\n",
      "  training ROC AUC:\t\t0.548 %\n",
      "  validation loss:\t\t0.694064\n",
      "  validation accuracy:\t\t0.497 %\n",
      "  validation ROC AUC:\t\t0.519 %\n",
      "Epoch 2 of 100 took 10.718s\n",
      "  training loss:\t\t3.622323\n",
      "  training accuracy:\t\t0.52 %\n",
      "  training ROC AUC:\t\t0.528 %\n",
      "  validation loss:\t\t0.671854\n",
      "  validation accuracy:\t\t0.564 %\n",
      "  validation ROC AUC:\t\t0.738 %\n",
      "Epoch 3 of 100 took 10.748s\n",
      "  training loss:\t\t0.957583\n",
      "  training accuracy:\t\t0.57 %\n",
      "  training ROC AUC:\t\t0.581 %\n",
      "  validation loss:\t\t0.625092\n",
      "  validation accuracy:\t\t0.607 %\n",
      "  validation ROC AUC:\t\t0.794 %\n",
      "Epoch 4 of 100 took 10.758s\n",
      "  training loss:\t\t0.839664\n",
      "  training accuracy:\t\t0.62 %\n",
      "  training ROC AUC:\t\t0.651 %\n",
      "  validation loss:\t\t0.493290\n",
      "  validation accuracy:\t\t0.782 %\n",
      "  validation ROC AUC:\t\t0.861 %\n",
      "Epoch 5 of 100 took 10.775s\n",
      "  training loss:\t\t0.740147\n",
      "  training accuracy:\t\t0.67 %\n",
      "  training ROC AUC:\t\t0.726 %\n",
      "  validation loss:\t\t0.453494\n",
      "  validation accuracy:\t\t0.793 %\n",
      "  validation ROC AUC:\t\t0.884 %\n",
      "Epoch 6 of 100 took 10.749s\n",
      "  training loss:\t\t0.589877\n",
      "  training accuracy:\t\t0.72 %\n",
      "  training ROC AUC:\t\t0.790 %\n",
      "  validation loss:\t\t0.551869\n",
      "  validation accuracy:\t\t0.715 %\n",
      "  validation ROC AUC:\t\t0.865 %\n",
      "Epoch 7 of 100 took 10.826s\n",
      "  training loss:\t\t0.683715\n",
      "  training accuracy:\t\t0.75 %\n",
      "  training ROC AUC:\t\t0.826 %\n",
      "  validation loss:\t\t0.406325\n",
      "  validation accuracy:\t\t0.833 %\n",
      "  validation ROC AUC:\t\t0.905 %\n",
      "Epoch 8 of 100 took 10.797s\n",
      "  training loss:\t\t0.479985\n",
      "  training accuracy:\t\t0.76 %\n",
      "  training ROC AUC:\t\t0.852 %\n",
      "  validation loss:\t\t0.420401\n",
      "  validation accuracy:\t\t0.811 %\n",
      "  validation ROC AUC:\t\t0.910 %\n",
      "Epoch 9 of 100 took 10.860s\n",
      "  training loss:\t\t0.453435\n",
      "  training accuracy:\t\t0.79 %\n",
      "  training ROC AUC:\t\t0.871 %\n",
      "  validation loss:\t\t0.820885\n",
      "  validation accuracy:\t\t0.569 %\n",
      "  validation ROC AUC:\t\t0.845 %\n",
      "Epoch 10 of 100 took 10.802s\n",
      "  training loss:\t\t0.425584\n",
      "  training accuracy:\t\t0.79 %\n",
      "  training ROC AUC:\t\t0.885 %\n",
      "  validation loss:\t\t0.337076\n",
      "  validation accuracy:\t\t0.850 %\n",
      "  validation ROC AUC:\t\t0.929 %\n",
      "Epoch 11 of 100 took 10.810s\n",
      "  training loss:\t\t0.426371\n",
      "  training accuracy:\t\t0.81 %\n",
      "  training ROC AUC:\t\t0.892 %\n",
      "  validation loss:\t\t0.370094\n",
      "  validation accuracy:\t\t0.830 %\n",
      "  validation ROC AUC:\t\t0.927 %\n",
      "Epoch 12 of 100 took 10.887s\n",
      "  training loss:\t\t0.409283\n",
      "  training accuracy:\t\t0.81 %\n",
      "  training ROC AUC:\t\t0.896 %\n",
      "  validation loss:\t\t0.342031\n",
      "  validation accuracy:\t\t0.849 %\n",
      "  validation ROC AUC:\t\t0.935 %\n",
      "Epoch 13 of 100 took 10.963s\n",
      "  training loss:\t\t0.393786\n",
      "  training accuracy:\t\t0.82 %\n",
      "  training ROC AUC:\t\t0.905 %\n",
      "  validation loss:\t\t0.314756\n",
      "  validation accuracy:\t\t0.861 %\n",
      "  validation ROC AUC:\t\t0.939 %\n",
      "Epoch 14 of 100 took 10.899s\n",
      "  training loss:\t\t0.395964\n",
      "  training accuracy:\t\t0.83 %\n",
      "  training ROC AUC:\t\t0.906 %\n",
      "  validation loss:\t\t0.338243\n",
      "  validation accuracy:\t\t0.853 %\n",
      "  validation ROC AUC:\t\t0.938 %\n",
      "Epoch 15 of 100 took 11.013s\n",
      "  training loss:\t\t0.371519\n",
      "  training accuracy:\t\t0.83 %\n",
      "  training ROC AUC:\t\t0.915 %\n",
      "  validation loss:\t\t0.335417\n",
      "  validation accuracy:\t\t0.866 %\n",
      "  validation ROC AUC:\t\t0.938 %\n",
      "Epoch 16 of 100 took 11.081s\n",
      "  training loss:\t\t0.366230\n",
      "  training accuracy:\t\t0.83 %\n",
      "  training ROC AUC:\t\t0.917 %\n",
      "  validation loss:\t\t0.316637\n",
      "  validation accuracy:\t\t0.864 %\n",
      "  validation ROC AUC:\t\t0.944 %\n",
      "Epoch 17 of 100 took 10.882s\n",
      "  training loss:\t\t0.364330\n",
      "  training accuracy:\t\t0.84 %\n",
      "  training ROC AUC:\t\t0.920 %\n",
      "  validation loss:\t\t0.361812\n",
      "  validation accuracy:\t\t0.851 %\n",
      "  validation ROC AUC:\t\t0.936 %\n",
      "Epoch 18 of 100 took 10.903s\n",
      "  training loss:\t\t0.354243\n",
      "  training accuracy:\t\t0.84 %\n",
      "  training ROC AUC:\t\t0.922 %\n",
      "  validation loss:\t\t0.338964\n",
      "  validation accuracy:\t\t0.840 %\n",
      "  validation ROC AUC:\t\t0.945 %\n",
      "Epoch 19 of 100 took 10.880s\n",
      "  training loss:\t\t0.342266\n",
      "  training accuracy:\t\t0.85 %\n",
      "  training ROC AUC:\t\t0.929 %\n",
      "  validation loss:\t\t0.403206\n",
      "  validation accuracy:\t\t0.839 %\n",
      "  validation ROC AUC:\t\t0.941 %\n",
      "Epoch 20 of 100 took 10.944s\n",
      "  training loss:\t\t0.348135\n",
      "  training accuracy:\t\t0.85 %\n",
      "  training ROC AUC:\t\t0.926 %\n",
      "  validation loss:\t\t0.302486\n",
      "  validation accuracy:\t\t0.863 %\n",
      "  validation ROC AUC:\t\t0.949 %\n",
      "Epoch 21 of 100 took 10.903s\n",
      "  training loss:\t\t0.329792\n",
      "  training accuracy:\t\t0.85 %\n",
      "  training ROC AUC:\t\t0.934 %\n",
      "  validation loss:\t\t0.286976\n",
      "  validation accuracy:\t\t0.876 %\n",
      "  validation ROC AUC:\t\t0.949 %\n",
      "Epoch 22 of 100 took 10.967s\n",
      "  training loss:\t\t0.325743\n",
      "  training accuracy:\t\t0.86 %\n",
      "  training ROC AUC:\t\t0.935 %\n",
      "  validation loss:\t\t0.376402\n",
      "  validation accuracy:\t\t0.831 %\n",
      "  validation ROC AUC:\t\t0.941 %\n",
      "Epoch 23 of 100 took 11.044s\n",
      "  training loss:\t\t0.312165\n",
      "  training accuracy:\t\t0.86 %\n",
      "  training ROC AUC:\t\t0.940 %\n",
      "  validation loss:\t\t0.263122\n",
      "  validation accuracy:\t\t0.883 %\n",
      "  validation ROC AUC:\t\t0.957 %\n",
      "Epoch 24 of 100 took 11.141s\n",
      "  training loss:\t\t0.328671\n",
      "  training accuracy:\t\t0.85 %\n",
      "  training ROC AUC:\t\t0.935 %\n",
      "  validation loss:\t\t0.278532\n",
      "  validation accuracy:\t\t0.883 %\n",
      "  validation ROC AUC:\t\t0.956 %\n",
      "Epoch 25 of 100 took 11.119s\n",
      "  training loss:\t\t0.334250\n",
      "  training accuracy:\t\t0.85 %\n",
      "  training ROC AUC:\t\t0.935 %\n",
      "  validation loss:\t\t0.689058\n",
      "  validation accuracy:\t\t0.738 %\n",
      "  validation ROC AUC:\t\t0.930 %\n",
      "Epoch 26 of 100 took 11.048s\n",
      "  training loss:\t\t0.305369\n",
      "  training accuracy:\t\t0.87 %\n",
      "  training ROC AUC:\t\t0.944 %\n",
      "  validation loss:\t\t0.255216\n",
      "  validation accuracy:\t\t0.885 %\n",
      "  validation ROC AUC:\t\t0.960 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a2aaaf54bd23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0my_ref_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mbatch_ce\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[0mbatch_ce\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[0mbatch_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    911\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 913\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    914\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "metrics = defaultdict(dict)\n",
    "\n",
    "import time\n",
    "num_epochs = 50\n",
    "batch_size = 50\n",
    "\n",
    "# We iterate over epochs:\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    y_pred_batches = []\n",
    "    y_ref_batches = []\n",
    "    for batch in iterate_minibatches(Xtr, Ytr, batch_size, shuffle=True):\n",
    "        batch_ce,batch_acc,pred_batch= train_fun(*batch)\n",
    "        train_err +=batch_ce\n",
    "        train_acc +=batch_acc\n",
    "        train_batches += 1\n",
    "        y_pred_batches.append(pred_batch)\n",
    "        y_ref_batches.append(batch[1])\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_batches)\n",
    "    y_ref = np.concatenate(y_ref_batches)\n",
    "    train_auc = roc_auc_score(y_ref,y_pred)\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    y_pred_batches = []\n",
    "    y_ref_batches = []\n",
    "    for batch in iterate_minibatches(Xts, Yts, batch_size, shuffle=False):\n",
    "        err, acc,pred_batch = eval_fun(*batch)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "        y_pred_batches.append(pred_batch)\n",
    "        y_ref_batches.append(batch[1])\n",
    "\n",
    "    y_pred = np.concatenate(y_pred_batches)\n",
    "    y_ref = np.concatenate(y_ref_batches)\n",
    "    val_auc = roc_auc_score(y_ref,y_pred)\n",
    "\n",
    "    metrics[\"acc_train\"][epoch] = train_acc/train_batches\n",
    "    metrics[\"auc_train\"][epoch] = train_auc\n",
    "    metrics[\"acc_test\"][epoch] = val_acc/val_batches\n",
    "    metrics[\"auc_test\"][epoch] = val_auc\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  training accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches))\n",
    "    print(\"  training ROC AUC:\\t\\t{:.3f} %\".format(\n",
    "        train_auc))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.3f} %\".format(\n",
    "        val_acc / val_batches))\n",
    "    print(\"  validation ROC AUC:\\t\\t{:.3f} %\".format(\n",
    "        val_auc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for metric_name in metrics:\n",
    "    \n",
    "    plt.plot(*zip(*sorted(metrics[metric_name].items())),label = metric_name)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_err = 0\n",
    "val_acc = 0\n",
    "val_batches = 0\n",
    "y_pred_batches = []\n",
    "y_ref_batches = []\n",
    "\n",
    "for batch in iterate_minibatches(Xts, Yts, batch_size, shuffle=False):\n",
    "    err, acc,pred_batch = eval_fun(*batch)\n",
    "    val_err += err\n",
    "    val_acc += acc\n",
    "    val_batches += 1\n",
    "    y_pred_batches.append(pred_batch)\n",
    "    y_ref_batches.append(batch[1])\n",
    "\n",
    "y_pred = np.concatenate(y_pred_batches)\n",
    "y_ref = np.concatenate(y_ref_batches)\n",
    "val_auc = roc_auc_score(y_ref,y_pred)\n",
    "\n",
    "print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "print(\"  validation accuracy:\\t\\t{:.3f} %\".format(\n",
    "    val_acc*100 / val_batches))\n",
    "print(\"  validation ROC AUC:\\t\\t{:.3f} %\".format(\n",
    "    val_auc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

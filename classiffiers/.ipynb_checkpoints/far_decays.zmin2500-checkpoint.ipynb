{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os,sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "experiment_name = \"baseline.classifier.cnn_4_retinas.vggsmall\"\n",
    "metadata_path = \"../data/mined_retinas_full\"\n",
    "data_path = \"../data/sig56/\"\n",
    "\n",
    "reference_df_path = \"../data/decays/far_ks_counts_56.csv\"\n",
    "\n",
    "\n",
    "generate_metadata = not os.path.exists(metadata_path)\n",
    "\n",
    "if generate_metadata:\n",
    "    print \"Metadata does not exist. This run might be MUCH longer due to preprocessing the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"device=gpu2\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 2: Tesla K40m (CNMeM is disabled, CuDNN 4004)\n"
     ]
    }
   ],
   "source": [
    "#import theano stack\n",
    "%env THEANO_FLAGS=\"device=gpu2\"\n",
    "\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lib.retina_compiled import retinize_events\n",
    "\n",
    "floatX = theano.config.floatX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess/Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lib.retina_compiled import retina_view\n",
    "\n",
    "retina_images_path = os.path.join(metadata_path,\"retina_images.npy\")\n",
    "answers_path = os.path.join(metadata_path,\"decay_counts.npy\")\n",
    "\n",
    "\n",
    "#event names\n",
    "df_ref = pd.DataFrame.from_csv(reference_df_path,index_col=None)\n",
    "y = df_ref.relevant_decay_count.values >0\n",
    "\n",
    "\n",
    "if generate_metadata:\n",
    "    \n",
    "\n",
    "\n",
    "    param_df = pd.DataFrame.from_csv(\"./baseline_mined_retina_params.csv\")\n",
    "    param_df.xdim=32\n",
    "    param_df.ydim=32\n",
    "    retinas = [retina_view(*params) for params in param_df.values]\n",
    "\n",
    "    X = retinize_events(df_ref.X_filename.values,\n",
    "                             data_path,retina_views=retinas,\n",
    "                             max_hits_block=15000,report_rate=100)\n",
    "    \n",
    "    \n",
    "    os.mkdir(metadata_path)\n",
    "    np.save(retina_images_path,X)\n",
    "    \n",
    "    generate_metadata = False\n",
    "else:\n",
    "    #load metadata\n",
    "    X = np.load(retina_images_path)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.reshape([len(X),-1,32,32])\n",
    "\n",
    "X = X.astype('float32')\n",
    "y = y.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23778,) (7926,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "Xtr, Xts, Ytr,Yts = train_test_split(X,y,test_size=0.25,random_state=1337)\n",
    "\n",
    "print Ytr.shape,Yts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/thenv/local/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:701: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-15a6dfb6cf2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mYts_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mYtr_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1581\u001b[0m                       \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m                       )\n\u001b[1;32m-> 1583\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1584\u001b[0m             for train, test in folds)\n\u001b[0;32m   1585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    798\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    656\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[1;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0mintercept_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, copy, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[0;32m    691\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m                     iprint=(verbose > 0) - 1, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[0;32m    694\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m                 \u001b[1;31m# old scipy doesn't have maxiter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 193\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    194\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    195\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    328\u001b[0m                 \u001b[1;31m# minimization routine wants f and g at the current x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;34m'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[1;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mz0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Case where we fit the intercept.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jheuristic/thenv/local/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr = LogisticRegressionCV(verbose=True).fit(Xtr.reshape([len(Xtr),-1]),Ytr)\n",
    "Yts_pred = lr.predict_proba(Xts.reshape([len(Xts),-1]))[:,1]\n",
    "Ytr_pred = lr.predict_proba(Xtr.reshape([len(Xtr),-1]))[:,1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "print accuracy_score(Yts,Yts_pred>0.5), roc_auc_score(Yts,Yts_pred)\n",
    "print  accuracy_score(Yts, Yts_prev>0.5), roc_auc_score(Ytr,Ytr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dim = (None,)+X.shape[1:]\n",
    "\n",
    "retina_dim = (None,1) + X.shape[2:]\n",
    "\n",
    "retina_images = T.tensor4(\"input_images\",\"floatX\")\n",
    "\n",
    "any_interesting_decays = T.ivector(\"mctruith_any_decays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concatenated_retinas = retina_images.reshape([retina_images.shape[0],1,-1,retina_images.shape[-1]])\n",
    "\n",
    "concatenated_dim = (None,1,np.prod(X.shape[1:-1]),X.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import MaxPool2DLayer as PoolLayer\n",
    "from lasagne.layers import DenseLayer, DropoutLayer\n",
    "\n",
    "#nn where each retina is processed with a separate CNN\n",
    "\n",
    "net = {}\n",
    "\n",
    "net['input'] = InputLayer(concatenated_dim,input_var=concatenated_retinas)\n",
    "net['conv1_1'] = ConvLayer(\n",
    "            net['input'], 256, 5, pad=1, flip_filters=False)\n",
    "net['pool1'] = PoolLayer(net['conv1_1'], 3)\n",
    "net['conv2_1'] = ConvLayer(\n",
    "            net['pool1'], 256, 5, pad=1, flip_filters=False)\n",
    "net['pool2'] = PoolLayer(net['conv2_1'], 3)\n",
    "    \n",
    "net['fc6'] = DenseLayer(net[\"pool2\"], num_units=1024)\n",
    "#net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.1)\n",
    "\n",
    "net['out'] = DenseLayer(net['fc6'], num_units=2, \n",
    "                        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, W, b, W, b]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = lasagne.layers.get_all_params(net[\"out\"],trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_prediction = lasagne.layers.get_output(net[\"out\"])\n",
    "train_loss_ce = lasagne.objectives.categorical_crossentropy(train_prediction,any_interesting_decays).mean()\n",
    "train_accuracy = lasagne.objectives.categorical_accuracy(train_prediction,any_interesting_decays).mean()\n",
    "updates = lasagne.updates.adadelta(train_loss_ce,weights,learning_rate=0.01) \n",
    "#ik that lr does not matter. I just dont want an explosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fun = theano.function([retina_images,any_interesting_decays],[train_loss_ce,train_accuracy,train_prediction[:,1]], updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = lasagne.layers.get_output(net[\"out\"],deterministic=True)\n",
    "loss_ce = lasagne.objectives.categorical_crossentropy(prediction,any_interesting_decays).mean()\n",
    "accuracy = lasagne.objectives.categorical_accuracy(prediction,any_interesting_decays).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_fun = theano.function([retina_images,any_interesting_decays], [loss_ce,accuracy,prediction[:,1]])\n",
    "predict_fun = theano.function([retina_images],prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main loop\n",
    "* almost copies the layout of lasagne basic training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False,crop_at=None):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if crop_at == start_idx:\n",
    "            break\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 253.685s\n",
      "  training loss:\t\t4.361177\n",
      "  training accuracy:\t\t78.36 %\n",
      "  training ROC AUC:\t\t0.508 %\n",
      "  validation loss:\t\t0.522183\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.502 %\n",
      "Epoch 2 of 100 took 252.513s\n",
      "  training loss:\t\t0.536666\n",
      "  training accuracy:\t\t85.18 %\n",
      "  training ROC AUC:\t\t0.508 %\n",
      "  validation loss:\t\t0.421423\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.505 %\n",
      "Epoch 3 of 100 took 252.220s\n",
      "  training loss:\t\t0.425064\n",
      "  training accuracy:\t\t87.22 %\n",
      "  training ROC AUC:\t\t0.506 %\n",
      "  validation loss:\t\t0.404273\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.507 %\n",
      "Epoch 4 of 100 took 252.819s\n",
      "  training loss:\t\t0.412260\n",
      "  training accuracy:\t\t87.44 %\n",
      "  training ROC AUC:\t\t0.497 %\n",
      "  validation loss:\t\t0.453203\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.526 %\n",
      "Epoch 5 of 100 took 252.345s\n",
      "  training loss:\t\t0.403991\n",
      "  training accuracy:\t\t87.45 %\n",
      "  training ROC AUC:\t\t0.502 %\n",
      "  validation loss:\t\t0.399211\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.509 %\n",
      "Epoch 6 of 100 took 253.264s\n",
      "  training loss:\t\t0.399036\n",
      "  training accuracy:\t\t87.44 %\n",
      "  training ROC AUC:\t\t0.503 %\n",
      "  validation loss:\t\t0.395740\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.500 %\n",
      "Epoch 7 of 100 took 253.186s\n",
      "  training loss:\t\t0.392852\n",
      "  training accuracy:\t\t87.45 %\n",
      "  training ROC AUC:\t\t0.504 %\n",
      "  validation loss:\t\t0.405514\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.506 %\n",
      "Epoch 8 of 100 took 252.819s\n",
      "  training loss:\t\t0.389306\n",
      "  training accuracy:\t\t87.44 %\n",
      "  training ROC AUC:\t\t0.505 %\n",
      "  validation loss:\t\t0.391762\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.504 %\n",
      "Epoch 9 of 100 took 251.843s\n",
      "  training loss:\t\t0.386444\n",
      "  training accuracy:\t\t87.44 %\n",
      "  training ROC AUC:\t\t0.509 %\n",
      "  validation loss:\t\t0.388606\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.492 %\n",
      "Epoch 10 of 100 took 248.855s\n",
      "  training loss:\t\t0.383654\n",
      "  training accuracy:\t\t87.45 %\n",
      "  training ROC AUC:\t\t0.507 %\n",
      "  validation loss:\t\t0.387554\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.500 %\n",
      "Epoch 11 of 100 took 249.317s\n",
      "  training loss:\t\t0.381746\n",
      "  training accuracy:\t\t87.45 %\n",
      "  training ROC AUC:\t\t0.513 %\n",
      "  validation loss:\t\t0.390613\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.491 %\n",
      "Epoch 12 of 100 took 250.169s\n",
      "  training loss:\t\t0.380380\n",
      "  training accuracy:\t\t87.45 %\n",
      "  training ROC AUC:\t\t0.517 %\n",
      "  validation loss:\t\t0.418018\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.499 %\n",
      "Epoch 13 of 100 took 249.236s\n",
      "  training loss:\t\t0.380986\n",
      "  training accuracy:\t\t87.44 %\n",
      "  training ROC AUC:\t\t0.516 %\n",
      "  validation loss:\t\t0.388037\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.486 %\n",
      "Epoch 14 of 100 took 248.607s\n",
      "  training loss:\t\t0.379184\n",
      "  training accuracy:\t\t87.45 %\n",
      "  training ROC AUC:\t\t0.524 %\n",
      "  validation loss:\t\t0.389345\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.496 %\n",
      "Epoch 15 of 100 took 248.651s\n",
      "  training loss:\t\t0.379503\n",
      "  training accuracy:\t\t87.46 %\n",
      "  training ROC AUC:\t\t0.520 %\n",
      "  validation loss:\t\t0.387398\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.492 %\n",
      "Epoch 16 of 100 took 249.289s\n",
      "  training loss:\t\t0.378164\n",
      "  training accuracy:\t\t87.46 %\n",
      "  training ROC AUC:\t\t0.534 %\n",
      "  validation loss:\t\t0.386071\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.488 %\n",
      "Epoch 17 of 100 took 249.370s\n",
      "  training loss:\t\t0.378485\n",
      "  training accuracy:\t\t87.45 %\n",
      "  training ROC AUC:\t\t0.526 %\n",
      "  validation loss:\t\t0.386440\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.488 %\n",
      "Epoch 18 of 100 took 249.669s\n",
      "  training loss:\t\t0.378654\n",
      "  training accuracy:\t\t87.45 %\n",
      "  training ROC AUC:\t\t0.534 %\n",
      "  validation loss:\t\t0.421379\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.498 %\n",
      "Epoch 19 of 100 took 233.472s\n",
      "  training loss:\t\t0.379059\n",
      "  training accuracy:\t\t87.44 %\n",
      "  training ROC AUC:\t\t0.528 %\n",
      "  validation loss:\t\t0.390329\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.492 %\n",
      "Epoch 20 of 100 took 197.366s\n",
      "  training loss:\t\t0.378152\n",
      "  training accuracy:\t\t87.44 %\n",
      "  training ROC AUC:\t\t0.529 %\n",
      "  validation loss:\t\t0.386768\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.496 %\n",
      "Epoch 21 of 100 took 196.771s\n",
      "  training loss:\t\t0.377891\n",
      "  training accuracy:\t\t87.46 %\n",
      "  training ROC AUC:\t\t0.534 %\n",
      "  validation loss:\t\t0.387019\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.479 %\n",
      "Epoch 22 of 100 took 196.724s\n",
      "  training loss:\t\t0.379482\n",
      "  training accuracy:\t\t87.43 %\n",
      "  training ROC AUC:\t\t0.528 %\n",
      "  validation loss:\t\t0.385514\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.493 %\n",
      "Epoch 23 of 100 took 196.822s\n",
      "  training loss:\t\t0.377348\n",
      "  training accuracy:\t\t87.46 %\n",
      "  training ROC AUC:\t\t0.540 %\n",
      "  validation loss:\t\t0.386171\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.487 %\n",
      "Epoch 24 of 100 took 196.669s\n",
      "  training loss:\t\t0.378180\n",
      "  training accuracy:\t\t87.44 %\n",
      "  training ROC AUC:\t\t0.539 %\n",
      "  validation loss:\t\t0.387240\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.499 %\n",
      "Epoch 25 of 100 took 196.946s\n",
      "  training loss:\t\t0.377803\n",
      "  training accuracy:\t\t87.46 %\n",
      "  training ROC AUC:\t\t0.535 %\n",
      "  validation loss:\t\t0.386953\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.488 %\n",
      "Epoch 26 of 100 took 196.886s\n",
      "  training loss:\t\t0.377178\n",
      "  training accuracy:\t\t87.44 %\n",
      "  training ROC AUC:\t\t0.541 %\n",
      "  validation loss:\t\t0.385782\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.496 %\n",
      "Epoch 27 of 100 took 196.918s\n",
      "  training loss:\t\t0.376699\n",
      "  training accuracy:\t\t87.46 %\n",
      "  training ROC AUC:\t\t0.544 %\n",
      "  validation loss:\t\t0.397148\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.500 %\n",
      "Epoch 28 of 100 took 196.975s\n",
      "  training loss:\t\t0.376443\n",
      "  training accuracy:\t\t87.47 %\n",
      "  training ROC AUC:\t\t0.548 %\n",
      "  validation loss:\t\t0.390280\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.496 %\n",
      "Epoch 29 of 100 took 196.851s\n",
      "  training loss:\t\t0.376774\n",
      "  training accuracy:\t\t87.45 %\n",
      "  training ROC AUC:\t\t0.549 %\n",
      "  validation loss:\t\t0.386782\n",
      "  validation accuracy:\t\t87.14 %\n",
      "  validation ROC AUC:\t\t0.490 %\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "metrics = defaultdict(dict)\n",
    "\n",
    "import time\n",
    "num_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "# We iterate over epochs:\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    y_pred_batches = []\n",
    "    y_ref_batches = []\n",
    "    for batch in iterate_minibatches(Xtr, Ytr, batch_size, shuffle=True):\n",
    "        batch_ce,batch_acc,pred_batch= train_fun(*batch)\n",
    "        train_err +=batch_ce\n",
    "        train_acc +=batch_acc\n",
    "        train_batches += 1\n",
    "        y_pred_batches.append(pred_batch)\n",
    "        y_ref_batches.append(batch[1])\n",
    "        \n",
    "    y_pred = np.concatenate(y_pred_batches)\n",
    "    y_ref = np.concatenate(y_ref_batches)\n",
    "    train_auc = roc_auc_score(y_ref,y_pred)\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    y_pred_batches = []\n",
    "    y_ref_batches = []\n",
    "    for batch in iterate_minibatches(Xts, Yts, batch_size, shuffle=False):\n",
    "        err, acc,pred_batch = eval_fun(*batch)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "        y_pred_batches.append(pred_batch)\n",
    "        y_ref_batches.append(batch[1])\n",
    "\n",
    "    y_pred = np.concatenate(y_pred_batches)\n",
    "    y_ref = np.concatenate(y_ref_batches)\n",
    "    val_auc = roc_auc_score(y_ref,y_pred)\n",
    "\n",
    "    metrics[\"acc_train\"][epoch] = train_acc\n",
    "    metrics[\"auc_train\"][epoch] = train_auc\n",
    "    metrics[\"acc_test\"][epoch] = val_acc\n",
    "    metrics[\"auc_test\"][epoch] = val_auc\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  training accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  training ROC AUC:\\t\\t{:.3f} %\".format(\n",
    "        train_auc))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))\n",
    "    print(\"  validation ROC AUC:\\t\\t{:.3f} %\".format(\n",
    "        val_auc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# After training, we compute and print the test error:\n",
    "test_err = 0\n",
    "test_acc = 0\n",
    "test_batches = 0\n",
    "y_pred_batches = []\n",
    "y_ref_batches = []\n",
    "\n",
    "for batch in iterate_minibatches(Xts, Yts, batch_size, shuffle=False):\n",
    "    inputs, targets = batch\n",
    "    err, acc = eval_fun(inputs, targets)\n",
    "    test_err += err\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "    y_pred_batches.append(pred_batch)\n",
    "    y_ref_batches.append(batch[1])\n",
    "    \n",
    "y_pred = np.concatenate(y_pred_batches)\n",
    "y_ref = np.concatenate(y_ref_batches)\n",
    "test_auc = roc_auc_score(y_ref,y_pred)\n",
    "\n",
    "\n",
    "print(\"Final results:\")\n",
    "print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(test_acc / test_batches * 100))\n",
    "print(\"  validation ROC AUC:\\t\\t{:.3f} %\".format(val_auc*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,sys\n",
    "sys.path.append(\"..\")\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from config import from_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sig_folders = [from_data(\"sig56/\")]\n",
    "\n",
    "decay_df_paths = [from_data(\"decays/KS_decays_5.csv\"),\n",
    "                  from_data(\"decays/KS_decays_6.csv\")]\n",
    "\n",
    "output_df_name = from_data(\"decays/far_ks_counts_56.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = [fn  for sig_folder in sig_folders for fn in os.listdir(sig_folder) if fn.endswith(\".hits.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_tuples = map(lambda s: map(int,s.split('.')[0].split('_')),filenames)\n",
    "\n",
    "runIDs, eventIDs = zip(*id_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read decays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#auxilary functions to preprocess decay data\n",
    "import pandas as pd\n",
    "def decayQuality(decayString):\n",
    "    '''how orthodoxal KS is [lower = better]'''\n",
    "    particle_codes = decayString.split('&')\n",
    "    piplus_count = particle_codes.count('211')\n",
    "    piminus_count = particle_codes.count('-211')\n",
    "    \n",
    "    if piplus_count ==0 and piminus_count ==0: return float('inf')\n",
    "    \n",
    "    return len(particle_codes) - piplus_count - piminus_count\n",
    "def preprocess_decay_data(df_path,\n",
    "                          min_decay_z = 0,\n",
    "                          max_quality = 10,\n",
    "                          max_origin_distance=25000,\n",
    "                          min_flight_distance = 0,\n",
    "                          ):\n",
    "    \"\"\"load KS decay dataframe generated by /preprocess/KS_extractor.py \n",
    "    and filter out irrelevant decays (e.g. Ks->2pi0)\"\"\"\n",
    "    \n",
    "    print \"reading\",df_path\n",
    "\n",
    "    \n",
    "    decay_df = pd.DataFrame.from_csv(df_path,index_col=None,sep=';')\n",
    "    decay_df.children = decay_df.children.astype(np.string_)\n",
    "\n",
    "    print len(np.unique( (decay_df.runID,decay_df.eventID))),'events in dataframe'\n",
    "\n",
    "\n",
    "    decay_df[\"originDistanceZ\"] = (decay_df.originZ - decay_df.primaryZ)\n",
    "    \n",
    "    decay_df[\"decayQuality\"] = map(decayQuality,decay_df.children)\n",
    "    \n",
    "    decay_vectors = decay_df[[\"decayX\",\"decayY\",\"decayZ\"]].values\n",
    "    origin_vectors = decay_df[[\"originX\",\"originY\",\"originZ\"]].values\n",
    "    decay_df[\"flightDistance\"] = np.linalg.norm(decay_vectors-origin_vectors,axis=1)\n",
    "    \n",
    "    \n",
    "    isGood = np.logical_and.reduce([\n",
    "        decay_df.decayQuality <=max_quality,\n",
    "        decay_df.originDistanceZ.abs() <= max_origin_distance,\n",
    "        decay_df.flightDistance >= min_flight_distance,\n",
    "        decay_df.decayZ >= min_decay_z\n",
    "    ])\n",
    "    good_decay_df = decay_df[isGood]\n",
    "    print len(np.unique( (good_decay_df.runID,good_decay_df.eventID))),'events left with relevant decays'\n",
    "    return good_decay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /srv/hd7/jheuristic/ksfinder_data/decays/KS_decays_5.csv\n",
      "17573 events in dataframe\n",
      "17545 events left with relevant decays\n",
      "reading /srv/hd7/jheuristic/ksfinder_data/decays/KS_decays_6.csv\n",
      "17664 events in dataframe\n",
      "17644 events left with relevant decays\n",
      "307310 relevant decays total in all dataframes\n",
      "grouping...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "decay_dataframe_shards = map(preprocess_decay_data,decay_df_paths)\n",
    "\n",
    "decays = pd.concat(decay_dataframe_shards)\n",
    "\n",
    "print len(decays),'relevant decays total in all dataframes'\n",
    "print 'grouping...'\n",
    "\n",
    "#function (runID(int),eventID(int)) -> decays for this pair(df)\n",
    "decay_groups = decays.groupby([\"runID\",\"eventID\"],as_index=True)\n",
    "\n",
    "#strip unused columns\n",
    "decay_groups = decay_groups[[u'decayX',u'decayY',u'decayZ',u'children',u'flightDistance']]\n",
    "\n",
    "#e.g. decay_groups.get_group((3695761 ,485762))\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.71 s, sys: 24 ms, total: 8.73 s\n",
      "Wall time: 8.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#aligning images with decays\n",
    "# sorry i'm just too lazy to implement joblib parallelism here, \n",
    "# even so, it takes a single tea cup to process 30k events\n",
    "\n",
    "\n",
    "#runIDs,eventIDs are left from retina image preprocessing phase\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "y_target = []\n",
    "for i,(runID,eventID,fname) in enumerate(zip(runIDs,eventIDs,filenames)):\n",
    "    X_list.append(fname.split('.')[0]) \n",
    "        \n",
    "    if (runID,eventID) not in decay_groups.groups:\n",
    "        y_list.append(None)\n",
    "        y_target.append(0)\n",
    "    else:\n",
    "        group=decay_groups.get_group((runID,eventID))\n",
    "        y_list.append(group)\n",
    "        y_target.append(len(group))\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref_df = pd.DataFrame({\"X_filename\":X_list,\"relevant_decay_count\":y_target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_df.to_csv(output_df_name,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99864370426444615"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ref_df.relevant_decay_count>0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

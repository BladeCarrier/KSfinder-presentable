{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time; \n",
    "\n",
    "#io\n",
    "import os\n",
    "import json\n",
    "\n",
    "#data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Hit level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "types = [\"ECAL\",\"HCAL\",\"IT\",\"OT\",\"TT\",\"VELOR1\",\"VELOR2\",\"VELOPHI1\",\"VELOPHI2\",\"MUON\",\"MUON2\"]\n",
    "type_code = {c:i for i,c in enumerate(types)}\n",
    "\n",
    "def collect_hits(evt,types_dict = type_code):\n",
    "    \"\"\"collect hits (np.array) from a json event dictionary\n",
    "    output: np.array([x,y,z,type_code]) of hits\"\"\"\n",
    "\n",
    "    arrays = []\n",
    "    \n",
    "    #calorimeters:0\n",
    "    for cal in \"ECAL\",\"HCAL\":\n",
    "        XYZ = [hit[1:4]+[types_dict[cal]] for hit in evt[cal]]\n",
    "        arrays.append(np.array(XYZ))\n",
    "    #triggers: 1\n",
    "    for trigger in \"TT\",\"OT\",\"IT\":\n",
    "        XYZ1 = [hit[0:3]+[types_dict[trigger]] for hit in evt[trigger]]\n",
    "        arrays.append(np.array(XYZ1))\n",
    "    #muon detector (x:2,x+dx:3)\n",
    "    if \"MUON\" in evt:\n",
    "        XYZmu = np.array([hit[::2]+[types_dict[\"MUON\"]] for hit in evt[\"MUON\"]])\n",
    "        arrays.append(XYZmu)\n",
    "\n",
    "        deltaXYZmu = np.array([hit[1::2]+[1] for hit in evt[\"MUON\"]])\n",
    "        XYZmu2 = XYZmu+deltaXYZmu\n",
    "        XYZmu2[:,-1] = types_dict[\"MUON2\"]\n",
    "        arrays.append(XYZmu2)\n",
    "    #velo detector (velor:4, velophi:5)\n",
    "    for velo in \"VELOR\",\"VELOPHI\":\n",
    "        XYZ1 = [hit[:3]+[types_dict[velo+\"1\"]] for hit in evt[velo]]\n",
    "        arrays.append(np.array(XYZ1))\n",
    "\n",
    "        XYZ2 = [hit[:3]+[types_dict[velo+\"2\"]] for hit in evt[velo]]\n",
    "        arrays.append(np.array(XYZ2))\n",
    "    #compose a single array\n",
    "    arrays = filter(lambda a:len(a)!=0,arrays)\n",
    "    points = np.vstack(arrays)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "def extract_hits(evt):\n",
    "\n",
    "    if len(evt[\"ECAL\"]):\n",
    "        hits = collect_hits(evt,type_code)\n",
    "        df = pandas.DataFrame(hits,columns = ['X','Y','Z','source'])\n",
    "        df[\"source\"] = np.array(types)[df[\"source\"].values.astype(int)]\n",
    "        return df\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_tracks(evt):\n",
    "    particle_dicts = evt[\"PARTICLES\"]\n",
    "    track_rows = []\n",
    "    for pdict in particle_dicts:\n",
    "        pdict = dict(pdict) #shallowcopy\n",
    "        track = pdict[\"track\"]\n",
    "        for i,(x,y,z) in enumerate(track):\n",
    "            pdict['x'+str(i)] = x\n",
    "            pdict['y'+str(i)] = y\n",
    "            pdict['z'+str(i)] = z\n",
    "        del pdict[\"track\"]\n",
    "        track_rows.append(pdict)\n",
    "    \n",
    "    df = pandas.DataFrame(track_rows)\n",
    "    return df        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(json_folder,outdir_tracks,outdir_hits,n_shards=1,shard_i=0,omit_tracks=False):\n",
    "    itr=0\n",
    "    names = filter(lambda fname: fname.endswith(\".json\"),os.listdir(json_folder))\n",
    "\n",
    "    names = names[shard_i::n_shards]\n",
    "    \n",
    "    try: os.mkdir(outdir_hits)\n",
    "    except:pass \n",
    "    try: os.mkdir(outdir_tracks)\n",
    "    except:pass \n",
    "    \n",
    "    paths = np.array(map(lambda fname: os.path.join(json_folder,fname),names))\n",
    "    #shuffle\n",
    "    paths = paths[np.argsort(np.random.random(size = len(paths)))]\n",
    "\n",
    "    for name,path in zip(names,paths):\n",
    "        eventid = name.split(\".\")[0]#runnumber_eventnumber\n",
    "        try:\n",
    "            evt = json.load(open(path))\n",
    "        except:\n",
    "            continue\n",
    "        hit_df = extract_hits(evt)\n",
    "\n",
    "        if hit_df is not False:\n",
    "\n",
    "            hit_df.to_csv(os.path.join(outdir_hits,eventid+\".hits.csv\"))\n",
    "            \n",
    "            if not omit_tracks:\n",
    "                track_df = extract_tracks(evt)\n",
    "                track_df.to_csv(os.path.join(outdir_tracks,eventid+\".tracks.csv\"))\n",
    "            itr+=1\n",
    "\n",
    "            if itr%100 ==0:\n",
    "                print itr, \"events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrm -rf /mnt/KSfinder/mc_bg/bg_jsons_*\\ntar -xvf /root/bg_down.tar.gz -C /mnt/KSfinder/mc_bg/\\nmv /mnt/KSfinder/mc_bg/bg_jsons_all/ /mnt/KSfinder/mc_bg/bg_jsons_down/\\ntar -xvf /root/bg_up.tar.gz -C /mnt/KSfinder/mc_bg/\\ntar -xvf /root/sig_jsns.tar.gz -C /mnt/KSfinder/mc_sig/\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "rm -rf /mnt/KSfinder/mc_bg/bg_jsons_*\n",
    "tar -xvf /root/bg_down.tar.gz -C /mnt/KSfinder/mc_bg/\n",
    "mv /mnt/KSfinder/mc_bg/bg_jsons_all/ /mnt/KSfinder/mc_bg/bg_jsons_down/\n",
    "tar -xvf /root/bg_up.tar.gz -C /mnt/KSfinder/mc_bg/\n",
    "tar -xvf /root/sig_jsns.tar.gz -C /mnt/KSfinder/mc_sig/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "n_shards = 1\n",
    "tasks =[\n",
    "    joblib.delayed(preprocess)(\n",
    "        json_folder= \"../data/jsons/bg_up\",\n",
    "        outdir_hits = \"../data/bg_up\",\n",
    "        outdir_tracks = \"../data/bg_up\",\n",
    "        n_shards= n_shards,\n",
    "        shard_i=i\n",
    "    )\n",
    "    for i in range(n_shards)\n",
    "]\n",
    "\n",
    "_=joblib.Parallel(n_jobs=1)(tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "n_shards = 1\n",
    "tasks =[\n",
    "    joblib.delayed(preprocess)(\n",
    "        json_folder= \"../data/jsons/bg_down\",\n",
    "        outdir_hits = \"../data/bg_down\",\n",
    "        outdir_tracks = \"../data/bg_down\",\n",
    "        n_shards= n_shards,\n",
    "        shard_i=i\n",
    "    )\n",
    "    for i in range(n_shards)\n",
    "]\n",
    "\n",
    "_=joblib.Parallel(n_jobs=1)(tasks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
